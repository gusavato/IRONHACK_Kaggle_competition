# IRONHACK_Kaggle competition

<div style="text-align:center">
    <img src="./images/kaggle.png" alt="portada">
</div>

## Indice:
1.[üìú Descripci√≥n](#descripcion)\
2.[‚è≥ Desarrollo](#desarrollo)\
3.[üî¨ Conclusiones](#conclusiones)\
4.[üìÅ Estructura](#Estructura)

## Descripci√≥n:<a name="descripcion"/>

Sexto proyecto en Ironhack, donde se participar√° en una competici√≥n de kaggle, y tendr√° como participantes a todos los alumnos del bootcamp. 

La [competici√≥n](https://www.kaggle.com/competitions/predict-the-price-for-laptops) consistir√° en la predicci√≥n del precio de ordenadores personales, a partir de una serie de caracter√≠sticas.

Para ello usaremos herramientas de Machine Learning, por lo que tendremos que limpiar y transformar los datos para lograr el objetivo.

## Desarrollo:<a name="desarrollo"/>

Realizaremos el proceso siguiendo los siguientes pasos:

1- En el notebook [EDA](https://github.com/gusavato/IRONHACK_Kaggle_competition/blob/main/jupyter/1%20-%20EDA.ipynb) partimos de los datos proporcionados por la competici√≥n, limpiaremos y prepararemos los datos para poder aplicar las transformaciones pertinentes de cara a entrenar un modelo de Machine Learning.

2- En el notebook [Transformaci√≥n](https://github.com/gusavato/IRONHACK_Kaggle_competition/blob/main/jupyter/2%20-%20Transformacion.ipynb) continuaremos con el proceso iniciado en el paso anterior, y normalizaremos y etiquetaremos distintas caracter√≠sticas para poder aplicar el modelo que consideremos m√°s adecuado. Aparte realizaremos un proceso de clusterizaci√≥n mediante K-Means con el objetivo de enriquecer los datos

3- En el √∫ltimo notebook [Creaci√≥n del modelo y entrenamiento](https://github.com/gusavato/IRONHACK_Kaggle_competition/blob/main/jupyter/3%20-%20Creaci%C3%B3n%20del%20modelo%20y%20entrenamiento%20.ipynb) aplicaremos modelos de Random Forest y seleccionaremos los par√°metros √≥ptimos mediante [RandomizeSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html).

Aparte alimentaremos el modelo con distintas combinaciones de caracter√≠sticas para intentar conseguir una predicci√≥n m√°s ajustada. Las combinaciones usadas son las siguientes:
- Teniendo en cuenta o no los outliers
- Etiquetando los clusters obtenidos en el apartado anterior
- Eliminando o no columnas con alta correlaci√≥n

## Conclusiones:<a name="conclusiones"/>

Tras realizar 24 predicciones obtenemos las siguientes conclusiones:
- El modelo de Random Forest ha obtenido valores de R2 elevados (por encima de 0.95)
- El error cuadr√°tico obtenido es casi 10 veces menor que la desviaci√≥n est√°ndar (6306430) de los datos proporcionados
- El haber hecho una clusterizaci√≥n no mejora signficativamente el modelo
- Si tenemos en cuenta los outliers (color amarillo) vemos un R2 m√°s elevado pero tambi√©n mayor MSE
- Si tenemos en cuenta las columnas con alta colinealidad, obtenemos mejores valores de R2 y menores de MSE

<div style="text-align:center">
    <img src="./images/R2vsMSE.png" alt="portada">
</div>

Tras subir las predicciones se ve que el error cuadr√°tico medio es 3 veces mayor al obtenido en el entrenamiento. Lo que nos indica que el modelo tiene un elevado grado de "overfit" como ya se hab√≠a predicho.

Por ello seleccionamos modelos de RandomizedSearchCV que hayan obtenido una calificaci√≥n intermedia de todas las iteraciones.

- Obtenemos valores similares de R2 y valores algo superiores de MSE, seguramente esto haga que los datos de test no salgan tan distintos
- Vemos de nuevo que la presencia de outliers hace que no tengamos el R2 m√°s elevado pero s√≠, valores m√°s controlados de MSE

<div style="text-align:center">
    <img src="./images/medium.png" alt="portada">
</div>

## Estructura:<a name="Estructura"/>

```
root 
|__ data/               # Contiene todos los csv usados en el repositorio            
|   |__ clean/          # Datos ya limpios
|   |__ muestras/       # Predicciones obtenidas
|   |__ raw/            # Datos originales de la competici√≥n
|   |__ transform/      # Datos ya transformados para aplicar modelo de ML
|
|__ images/             # Contiene la im√°genes que se han usado en el proyecto   
|
|__ jupyter/            # Alberga los notebooks usados en el proyecto
|
|__ .gitignore          # Archivo gitignore     
|
|__ README.md           # Descripci√≥n del proyecto